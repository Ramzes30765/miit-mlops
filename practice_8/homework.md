## 1. Запуск всего проекта в Docker

**Задача:**

* Собрать docker образ FastAPI-сервиса.
* Поднять Triton в отдельном контейнере.
* Написать `docker-compose.yml`, который:

  * поднимает Triton с модельным репозиторием,
  * поднимает FastAPI и прокидывает в него адрес Triton,
  * обеспечивает корректную сеть между ними.
  * batch_size минимум 2

**Критерий успешности:**

Один docker-compose up, после чего эндпоинт /infer доступен и отправляет запросы в Triton.

## 2. Переделать клиент под батч-запрос

**Задача:**

* В FastAPI добавить новый метод, например, `POST /infer_batch`.
* Принимать список изображений (`images: List[UploadFile]`) и собирать батч.
* Отправлять этот батч в Triton (один `infer` на весь батч).
* Возвращать список результатов для каждого элемента батча.

**Критерий успешности:**

При отправке N изображений в одном запросе все они корректно обрабатываются, а выходные массивы имеют форму `[N, …]`.


## 3. Настроить Triton на ансамблевую работу (детекция + сегментация)

**Задача (именно про ensemble в Triton):**

* Создать ensemble-модель, например, `yolo_ensemble`, которая:

  * принимает на вход изображение (или уже тензор/массив)

    * модель детекции (`yolo_det`),
    * модель сегментации (`yolo_seg`),
  * возвращает оба выхода.
* Описать это в `config.pbtxt` ensemble-модели (секция `ensemble_scheduling`).

**Критерий успешности:**
В Triton появляется третья модель (`yolo_ensemble`), и ваш FastAPI-клиент может вызвать её одним запросом и получить выходы обеих моделей.

## 4. NMS-код для детекции

**Задача:**

* Довести до рабочего состояния `postprocess_yolo_det`:

**Критерий успешности:**

На тестовом наборе изображений корректные bounding_box.

## 5. Добавить NMS / постобработку для сегментации

**Задача:**

* Написать простую постобработку для `yolo_seg`:

  * выделить маски по порогу/score,
  * при необходимости удалить дубликаты/перекрытия по IoU масок или по боксам масок,
  * вернуть итоговый набор масок/контуров + классы/скор.
* Интегрировать это либо в FastAPI, либо в Python backend.

**Критерий успешности:**

На тестовом наборе изображений корректные сегментационные маски.

## 6. Провести нагрузочное тестирование моделей в Triton через perf_analyzer

**Задача:**

1. Использовать `perf_analyzer` для оценки производительности вашего развёрнутого проекта (модели детекции, модели сегментации и ансамбля).
2. Провести **3–4 эксперимента** с разными параметрами:

   * разные batch size (`-b 1`, `-b 4`, `-b 8`, `-b 16`);
   * разные уровни параллельности (`--concurrency-range 1:8`);
   * сравнение `yolo_det`, `yolo_seg` и `yolo_ensemble`.
3. Для каждого эксперимента собрать ключевые метрики Triton:
4. Интерпретировать полученные результаты и подобрать оптимальные параметры запуска **для двух режимов работы**:

   * **режим минимальной latency**, но не превышающий порог:

     * 1 секунда (по умолчанию),
     * 5 секунд (если машина слабая и 1 секунда недостижима)

   * **режим максимального throughput** при разумной **latency** < **min_latency**.

# Допускется:

* Вместо моделей детекции и сегметации использовать LLM пайплайн(например перевод текста сразу на 2 языка)
