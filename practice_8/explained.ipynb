{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99da13b",
   "metadata": {},
   "source": [
    "```bash\n",
    "Speed: 1.0ms preprocess, 3.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
    "```\n",
    "1 + 3.8 + 1.6 = 6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe7afe",
   "metadata": {},
   "source": [
    "* delay 0\n",
    "* instance 1\n",
    "* batch 1\n",
    "* images:3,640,480\n",
    "* http\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab843b94",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 1\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 1\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 1869\n",
    "perf-1    |     Throughput: 51.9073 infer/sec\n",
    "perf-1    |     p50 latency: 18910 usec\n",
    "perf-1    |     p90 latency: 21428 usec\n",
    "perf-1    |     p95 latency: 22084 usec\n",
    "perf-1    |     p99 latency: 23554 usec\n",
    "perf-1    |     Avg HTTP time: 18756 usec (send/recv 6747 usec + response wait 12009 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 1869\n",
    "perf-1    |     Execution count: 1869\n",
    "perf-1    |     Successful request count: 1869\n",
    "perf-1    |     Avg request latency: 5920 usec (overhead 56 usec + queue 99 usec + compute input 191 usec + compute infer 5390 usec + compute output 182 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 1, throughput: 51.9073 infer/sec, latency 18910 usec\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aca7a6",
   "metadata": {},
   "source": [
    "* delay 0\n",
    "* instance 1\n",
    "* batch 1\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40ac0f",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 1\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 1\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3003\n",
    "perf-1    |     Throughput: 83.387 infer/sec\n",
    "perf-1    |     p50 latency: 11305 usec\n",
    "perf-1    |     p90 latency: 13222 usec\n",
    "perf-1    |     p95 latency: 14888 usec\n",
    "perf-1    |     p99 latency: 17462 usec\n",
    "perf-1    |     Avg gRPC time: 11355 usec ((un)marshal request/response 148 usec + response wait 11207 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 3003\n",
    "perf-1    |     Execution count: 3003\n",
    "perf-1    |     Successful request count: 3003\n",
    "perf-1    |     Avg request latency: 10218 usec (overhead 3434 usec + queue 107 usec + compute input 207 usec + compute infer 6187 usec + compute output 282 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 1, throughput: 83.387 infer/sec, latency 11305 usec\n",
    "perf-1 exited with code 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1ebb1",
   "metadata": {},
   "source": [
    "* delay 0\n",
    "* instance 1\n",
    "* C = 2...8\n",
    "* batch N\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076786c9",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 1\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Latency limit: 0 msec\n",
    "perf-1    |   Concurrency limit: 8 concurrent requests\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 2\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3674\n",
    "perf-1    |     Throughput: 101.824 infer/sec\n",
    "perf-1    |     p50 latency: 19025 usec\n",
    "perf-1    |     p90 latency: 22378 usec\n",
    "perf-1    |     p95 latency: 23631 usec\n",
    "perf-1    |     p99 latency: 28199 usec\n",
    "perf-1    |     Avg gRPC time: 19055 usec ((un)marshal request/response 149 usec + response wait 18906 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 3674\n",
    "perf-1    |     Execution count: 3674\n",
    "perf-1    |     Successful request count: 3674\n",
    "perf-1    |     Avg request latency: 16868 usec (overhead 2988 usec + queue 7170 usec + compute input 311 usec + compute infer 6163 usec + compute output 235 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 4\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3582\n",
    "perf-1    |     Throughput: 99.4027 infer/sec\n",
    "perf-1    |     p50 latency: 39763 usec\n",
    "perf-1    |     p90 latency: 45544 usec\n",
    "perf-1    |     p95 latency: 47563 usec\n",
    "perf-1    |     p99 latency: 51609 usec\n",
    "perf-1    |     Avg gRPC time: 39219 usec ((un)marshal request/response 163 usec + response wait 39056 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 3583\n",
    "perf-1    |     Execution count: 3484\n",
    "perf-1    |     Successful request count: 3583\n",
    "perf-1    |     Avg request latency: 36669 usec (overhead 3235 usec + queue 26283 usec + compute input 428 usec + compute infer 6456 usec + compute output 266 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 6\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 4262\n",
    "perf-1    |     Throughput: 117.929 infer/sec\n",
    "perf-1    |     p50 latency: 50179 usec\n",
    "perf-1    |     p90 latency: 57770 usec\n",
    "perf-1    |     p95 latency: 60040 usec\n",
    "perf-1    |     p99 latency: 66428 usec\n",
    "perf-1    |     Avg gRPC time: 50098 usec ((un)marshal request/response 175 usec + response wait 49923 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 4263\n",
    "perf-1    |     Execution count: 2842\n",
    "perf-1    |     Successful request count: 4263\n",
    "perf-1    |     Avg request latency: 46599 usec (overhead 3656 usec + queue 33193 usec + compute input 1215 usec + compute infer 8087 usec + compute output 448 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 8\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 4566\n",
    "perf-1    |     Throughput: 126.659 infer/sec\n",
    "perf-1    |     p50 latency: 62309 usec\n",
    "perf-1    |     p90 latency: 71491 usec\n",
    "perf-1    |     p95 latency: 74316 usec\n",
    "perf-1    |     p99 latency: 81658 usec\n",
    "perf-1    |     Avg gRPC time: 62345 usec ((un)marshal request/response 182 usec + response wait 62163 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 4566\n",
    "perf-1    |     Execution count: 2291\n",
    "perf-1    |     Successful request count: 4566\n",
    "perf-1    |     Avg request latency: 58582 usec (overhead 4371 usec + queue 42732 usec + compute input 1863 usec + compute infer 9035 usec + compute output 580 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 2, throughput: 101.824 infer/sec, latency 19025 usec\n",
    "perf-1    | Concurrency: 4, throughput: 99.4027 infer/sec, latency 39763 usec\n",
    "perf-1    | Concurrency: 6, throughput: 117.929 infer/sec, latency 50179 usec\n",
    "perf-1    | Concurrency: 8, throughput: 126.659 infer/sec, latency 62309 usec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d87b540",
   "metadata": {},
   "source": [
    "* delay 0\n",
    "* instance 2\n",
    "* C = 2...8\n",
    "* batch N\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38164d",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 1\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Latency limit: 0 msec\n",
    "perf-1    |   Concurrency limit: 8 concurrent requests\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 2\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3908\n",
    "perf-1    |     Throughput: 108.516 infer/sec\n",
    "perf-1    |     p50 latency: 17497 usec\n",
    "perf-1    |     p90 latency: 23944 usec\n",
    "perf-1    |     p95 latency: 26491 usec\n",
    "perf-1    |     p99 latency: 30857 usec\n",
    "perf-1    |     Avg gRPC time: 17801 usec ((un)marshal request/response 163 usec + response wait 17638 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 3908\n",
    "perf-1    |     Execution count: 3806\n",
    "perf-1    |     Successful request count: 3908\n",
    "perf-1    |     Avg request latency: 12968 usec (overhead 1759 usec + queue 532 usec + compute input 303 usec + compute infer 10003 usec + compute output 370 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 4\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 4442\n",
    "perf-1    |     Throughput: 123.291 infer/sec\n",
    "perf-1    |     p50 latency: 31241 usec\n",
    "perf-1    |     p90 latency: 40885 usec\n",
    "perf-1    |     p95 latency: 43707 usec\n",
    "perf-1    |     p99 latency: 49959 usec\n",
    "perf-1    |     Avg gRPC time: 31439 usec ((un)marshal request/response 176 usec + response wait 31263 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 4442\n",
    "perf-1    |     Execution count: 4333\n",
    "perf-1    |     Successful request count: 4442\n",
    "perf-1    |     Avg request latency: 25474 usec (overhead 1756 usec + queue 9191 usec + compute input 1012 usec + compute infer 13108 usec + compute output 406 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 6\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 4445\n",
    "perf-1    |     Throughput: 123.431 infer/sec\n",
    "perf-1    |     p50 latency: 47840 usec\n",
    "perf-1    |     p90 latency: 58123 usec\n",
    "perf-1    |     p95 latency: 61235 usec\n",
    "perf-1    |     p99 latency: 68631 usec\n",
    "perf-1    |     Avg gRPC time: 47732 usec ((un)marshal request/response 175 usec + response wait 47557 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 4446\n",
    "perf-1    |     Execution count: 4365\n",
    "perf-1    |     Successful request count: 4446\n",
    "perf-1    |     Avg request latency: 42111 usec (overhead 1921 usec + queue 25628 usec + compute input 1059 usec + compute infer 13110 usec + compute output 391 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 8\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 4719\n",
    "perf-1    |     Throughput: 130.937 infer/sec\n",
    "perf-1    |     p50 latency: 59944 usec\n",
    "perf-1    |     p90 latency: 73011 usec\n",
    "perf-1    |     p95 latency: 77292 usec\n",
    "perf-1    |     p99 latency: 86527 usec\n",
    "perf-1    |     Avg gRPC time: 60256 usec ((un)marshal request/response 173 usec + response wait 60083 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 4719\n",
    "perf-1    |     Execution count: 4133\n",
    "perf-1    |     Successful request count: 4719\n",
    "perf-1    |     Avg request latency: 54840 usec (overhead 2363 usec + queue 36875 usec + compute input 1314 usec + compute infer 13819 usec + compute output 468 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 2, throughput: 108.516 infer/sec, latency 17497 usec\n",
    "perf-1    | Concurrency: 4, throughput: 123.291 infer/sec, latency 31241 usec\n",
    "perf-1    | Concurrency: 6, throughput: 123.431 infer/sec, latency 47840 usec\n",
    "perf-1    | Concurrency: 8, throughput: 130.937 infer/sec, latency 59944 usec\n",
    "perf-1 exited with code 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550e93f",
   "metadata": {},
   "source": [
    "* delay 2000\n",
    "* instance 2\n",
    "* C = 2...8\n",
    "* batch 4, 8\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406fb56",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 1\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Latency limit: 0 msec\n",
    "perf-1    |   Concurrency limit: 8 concurrent requests\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 2\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3711\n",
    "perf-1    |     Throughput: 103.032 infer/sec\n",
    "perf-1    |     p50 latency: 18573 usec\n",
    "perf-1    |     p90 latency: 23659 usec\n",
    "perf-1    |     p95 latency: 25406 usec\n",
    "perf-1    |     p99 latency: 29896 usec\n",
    "perf-1    |     Avg gRPC time: 18763 usec ((un)marshal request/response 169 usec + response wait 18594 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 3711\n",
    "perf-1    |     Execution count: 2796\n",
    "perf-1    |     Successful request count: 3711\n",
    "perf-1    |     Avg request latency: 14554 usec (overhead 2382 usec + queue 2167 usec + compute input 720 usec + compute infer 8804 usec + compute output 480 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 4\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 5101\n",
    "perf-1    |     Throughput: 141.651 infer/sec\n",
    "perf-1    |     p50 latency: 27210 usec\n",
    "perf-1    |     p90 latency: 36171 usec\n",
    "perf-1    |     p95 latency: 39074 usec\n",
    "perf-1    |     p99 latency: 45611 usec\n",
    "perf-1    |     Avg gRPC time: 27342 usec ((un)marshal request/response 187 usec + response wait 27155 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 5101\n",
    "perf-1    |     Execution count: 3239\n",
    "perf-1    |     Successful request count: 5101\n",
    "perf-1    |     Avg request latency: 20917 usec (overhead 2684 usec + queue 3336 usec + compute input 1492 usec + compute infer 12664 usec + compute output 741 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 6\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 6043\n",
    "perf-1    |     Throughput: 167.731 infer/sec\n",
    "perf-1    |     p50 latency: 34774 usec\n",
    "perf-1    |     p90 latency: 46933 usec\n",
    "perf-1    |     p95 latency: 51062 usec\n",
    "perf-1    |     p99 latency: 59227 usec\n",
    "perf-1    |     Avg gRPC time: 35076 usec ((un)marshal request/response 200 usec + response wait 34876 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 6042\n",
    "perf-1    |     Execution count: 3130\n",
    "perf-1    |     Successful request count: 6042\n",
    "perf-1    |     Avg request latency: 28033 usec (overhead 3700 usec + queue 5586 usec + compute input 2407 usec + compute infer 15370 usec + compute output 970 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 8\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 6914\n",
    "perf-1    |     Throughput: 191.803 infer/sec\n",
    "perf-1    |     p50 latency: 40790 usec\n",
    "perf-1    |     p90 latency: 54507 usec\n",
    "perf-1    |     p95 latency: 58794 usec\n",
    "perf-1    |     p99 latency: 67531 usec\n",
    "perf-1    |     Avg gRPC time: 40870 usec ((un)marshal request/response 221 usec + response wait 40649 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 6916\n",
    "perf-1    |     Execution count: 2861\n",
    "perf-1    |     Successful request count: 6916\n",
    "perf-1    |     Avg request latency: 33712 usec (overhead 4763 usec + queue 7389 usec + compute input 3261 usec + compute infer 17060 usec + compute output 1238 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 2, throughput: 103.032 infer/sec, latency 18573 usec\n",
    "perf-1    | Concurrency: 4, throughput: 141.651 infer/sec, latency 27210 usec\n",
    "perf-1    | Concurrency: 6, throughput: 167.731 infer/sec, latency 34774 usec\n",
    "perf-1    | Concurrency: 8, throughput: 191.803 infer/sec, latency 40790 usec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c4701",
   "metadata": {},
   "source": [
    "* client-batch 2\n",
    "\n",
    "* delay 2000\n",
    "* instance 2\n",
    "* C = 2...8\n",
    "* batch 4, 8\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1440a9c",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 2\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Latency limit: 0 msec\n",
    "perf-1    |   Concurrency limit: 8 concurrent requests\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 2\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 2596\n",
    "perf-1    |     Throughput: 144.145 infer/sec\n",
    "perf-1    |     p50 latency: 27235 usec\n",
    "perf-1    |     p90 latency: 33815 usec\n",
    "perf-1    |     p95 latency: 35691 usec\n",
    "perf-1    |     p99 latency: 40380 usec\n",
    "perf-1    |     Avg gRPC time: 26838 usec ((un)marshal request/response 311 usec + response wait 26527 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 5192\n",
    "perf-1    |     Execution count: 2290\n",
    "perf-1    |     Successful request count: 2596\n",
    "perf-1    |     Avg request latency: 19102 usec (overhead 3152 usec + queue 2003 usec + compute input 1090 usec + compute infer 12086 usec + compute output 770 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 4\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3378\n",
    "perf-1    |     Throughput: 187.455 infer/sec\n",
    "perf-1    |     p50 latency: 41454 usec\n",
    "perf-1    |     p90 latency: 54487 usec\n",
    "perf-1    |     p95 latency: 58728 usec\n",
    "perf-1    |     p99 latency: 66825 usec\n",
    "perf-1    |     Avg gRPC time: 41930 usec ((un)marshal request/response 363 usec + response wait 41567 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 6758\n",
    "perf-1    |     Execution count: 2596\n",
    "perf-1    |     Successful request count: 3379\n",
    "perf-1    |     Avg request latency: 27776 usec (overhead 3503 usec + queue 4504 usec + compute input 2390 usec + compute infer 16281 usec + compute output 1097 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 6\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 3917\n",
    "perf-1    |     Throughput: 217.404 infer/sec\n",
    "perf-1    |     p50 latency: 54885 usec\n",
    "perf-1    |     p90 latency: 71779 usec\n",
    "perf-1    |     p95 latency: 76960 usec\n",
    "perf-1    |     p99 latency: 87123 usec\n",
    "perf-1    |     Avg gRPC time: 54400 usec ((un)marshal request/response 406 usec + response wait 53994 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 7834\n",
    "perf-1    |     Execution count: 2259\n",
    "perf-1    |     Successful request count: 3917\n",
    "perf-1    |     Avg request latency: 40502 usec (overhead 5428 usec + queue 8680 usec + compute input 4243 usec + compute infer 20568 usec + compute output 1582 usec)\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 8\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 4225\n",
    "perf-1    |     Throughput: 234.362 infer/sec\n",
    "perf-1    |     p50 latency: 70330 usec\n",
    "perf-1    |     p90 latency: 87335 usec\n",
    "perf-1    |     p95 latency: 92246 usec\n",
    "perf-1    |     p99 latency: 104187 usec\n",
    "perf-1    |     Avg gRPC time: 67212 usec ((un)marshal request/response 467 usec + response wait 66745 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 8444\n",
    "perf-1    |     Execution count: 1881\n",
    "perf-1    |     Successful request count: 4222\n",
    "perf-1    |     Avg request latency: 54100 usec (overhead 7314 usec + queue 12464 usec + compute input 6128 usec + compute infer 25973 usec + compute output 2219 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 2, throughput: 144.145 infer/sec, latency 27235 usec\n",
    "perf-1    | Concurrency: 4, throughput: 187.455 infer/sec, latency 41454 usec\n",
    "perf-1    | Concurrency: 6, throughput: 217.404 infer/sec, latency 54885 usec\n",
    "perf-1    | Concurrency: 8, throughput: 234.362 infer/sec, latency 70330 usec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3013f6",
   "metadata": {},
   "source": [
    "* client-batch 4\n",
    "\n",
    "* delay 2000\n",
    "* instance 1\n",
    "* C = 2\n",
    "* batch 4, 8\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18770886",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 4\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 2\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 1652\n",
    "perf-1    |     Throughput: 183.392 infer/sec\n",
    "perf-1    |     p50 latency: 42601 usec\n",
    "perf-1    |     p90 latency: 51254 usec\n",
    "perf-1    |     p95 latency: 53946 usec\n",
    "perf-1    |     p99 latency: 59466 usec\n",
    "perf-1    |     Avg gRPC time: 42347 usec ((un)marshal request/response 665 usec + response wait 41682 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 6608\n",
    "perf-1    |     Execution count: 1652\n",
    "perf-1    |     Successful request count: 1652\n",
    "perf-1    |     Avg request latency: 26423 usec (overhead 3836 usec + queue 6059 usec + compute input 1307 usec + compute infer 14059 usec + compute output 1160 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 2, throughput: 183.392 infer/sec, latency 42601 usec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b790dec",
   "metadata": {},
   "source": [
    "* client-batch 8\n",
    "\n",
    "* delay 2000\n",
    "* instance 1\n",
    "* C = 1\n",
    "* batch 4, 8\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec69b9e",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1    | *** Measurement Settings ***\n",
    "perf-1    |   Batch size: 8\n",
    "perf-1    |   Service Kind: TRITON\n",
    "perf-1    |   Using \"time_windows\" mode for stabilization\n",
    "perf-1    |   Stabilizing using p50latency and throughput\n",
    "perf-1    |   Measurement window: 10000 msec\n",
    "perf-1    |   Using synchronous calls for inference\n",
    "perf-1    | \n",
    "perf-1    | Request concurrency: 1\n",
    "perf-1    |   Client: \n",
    "perf-1    |     Request count: 667\n",
    "perf-1    |     Throughput: 148.177 infer/sec\n",
    "perf-1    |     p50 latency: 52816 usec\n",
    "perf-1    |     p90 latency: 59281 usec\n",
    "perf-1    |     p95 latency: 61478 usec\n",
    "perf-1    |     p99 latency: 64931 usec\n",
    "perf-1    |     Avg gRPC time: 51841 usec ((un)marshal request/response 1122 usec + response wait 50719 usec)\n",
    "perf-1    |   Server: \n",
    "perf-1    |     Inference count: 5344\n",
    "perf-1    |     Execution count: 668\n",
    "perf-1    |     Successful request count: 668\n",
    "perf-1    |     Avg request latency: 31754 usec (overhead 5202 usec + queue 128 usec + compute input 1964 usec + compute infer 22275 usec + compute output 2184 usec)\n",
    "perf-1    | \n",
    "perf-1    | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1    | Concurrency: 1, throughput: 148.177 infer/sec, latency 52816 usec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f58a5",
   "metadata": {},
   "source": [
    "* client-batch 8\n",
    "\n",
    "* delay 2000\n",
    "* instance 1\n",
    "* C = 1\n",
    "* batch 4, 8\n",
    "* images:3,640,480\n",
    "* grpc\n",
    "* trt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c79c0",
   "metadata": {},
   "source": [
    "```bash\n",
    "perf-1  | *** Measurement Settings ***\n",
    "perf-1  |   Batch size: 8\n",
    "perf-1  |   Service Kind: TRITON\n",
    "perf-1  |   Using \"time_windows\" mode for stabilization\n",
    "perf-1  |   Stabilizing using p50latency and throughput\n",
    "perf-1  |   Measurement window: 10000 msec\n",
    "perf-1  |   Using synchronous calls for inference\n",
    "perf-1  | \n",
    "perf-1  | Request concurrency: 1\n",
    "perf-1  |   Client: \n",
    "perf-1  |     Request count: 1099\n",
    "perf-1  |     Throughput: 244.138 infer/sec\n",
    "perf-1  |     p50 latency: 31832 usec\n",
    "perf-1  |     p90 latency: 35302 usec\n",
    "perf-1  |     p95 latency: 37071 usec\n",
    "perf-1  |     p99 latency: 42154 usec\n",
    "perf-1  |     Avg gRPC time: 31096 usec ((un)marshal request/response 1106 usec + response wait 29990 usec)\n",
    "perf-1  |   Server: \n",
    "perf-1  |     Inference count: 8800\n",
    "perf-1  |     Execution count: 1100\n",
    "perf-1  |     Successful request count: 1100\n",
    "perf-1  |     Avg request latency: 15752 usec (overhead 5971 usec + queue 132 usec + compute input 1886 usec + compute infer 6043 usec + compute output 1720 usec)\n",
    "perf-1  | \n",
    "perf-1  | Inferences/Second vs. Client p50 Batch Latency\n",
    "perf-1  | Concurrency: 1, throughput: 244.138 infer/sec, latency 31832 usec\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
